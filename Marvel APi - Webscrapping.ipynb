{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marvel API and webscrapping project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will use the Marvel API to retrieve data about one character, and then about all the characters in a series of your choice. This notebook uses the API as well as webscrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, if not done yet, create an account to receive your keys by following this link : https://developer.marvel.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can get familiar with the documentation here: https://developer.marvel.com/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, store your public and private keys into variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-ea8ead63d521>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-ea8ead63d521>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    publickey = #YOUR KEY\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "publickey = #YOUR KEY\n",
    "privatekey = #YOUR KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making your first request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the query parameters for each endpoint, the Marvel API expects you to include some additional information too in order to build a successful request. In particular, Marvel's API expects you to sign your requests. In particular, the API expects you to fill in the values for three parameters in all your requests\n",
    "    **apikey**: This parameter takes your public key.\n",
    "    **ts**: This parameter takes a timestamp in string form or any other long string which can change on a request-by-request basis.\n",
    "    **hash**: This parameter takes a MD5 hash of ts+privatekey+publickey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a timestampÂ¶\n",
    "You can obtain a timestamp for each request using the time library to . This library has a function called time that returns the current time. You can convert this output to a string to be used as a timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "ts = str(time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a MD5 hash\n",
    "In order to obtain the hash, you can use the hashlib library. The hash has to be applied over a code that corresponds to the concatenation of ts+privatekey+publickey. You can obtain it by running the cell below. Notice that the output is a long alphanumeric string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "code = ts+privatekey+publickey\n",
    "md5hash = hashlib.md5(code.encode('utf-8')).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your character name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_name = \"Loki\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send your query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "auth_url = 'https://gateway.marvel.com/v1/public/characters'\n",
    "# request body\n",
    "params = {'name': character_name,\n",
    "          'apikey': publickey,\n",
    "          'ts': ts,\n",
    "         'hash':md5hash}\n",
    "\n",
    "# POST the request\n",
    "response = requests.get(auth_url, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['data']['results'][0]['urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL wiki\n",
    "Write the code to identify the full url address for your character's wiki and format it so that it only includes the regular url. Store it in a new variable called url_wiki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this extract the wiki url\n",
    "url_wiki = response.json()['data']['results'][0]['urls'][1]['url']\n",
    "\n",
    "# this splits the url and takes the part we need\n",
    "url_wiki = url_wiki.split('?utm_campaign=')[0]\n",
    "\n",
    "url_wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poking around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy-paste the url your retrieved in the code above to your browser and take a look at the webpage. It contains a general profile for your character of choice, as well as a bio and some additional information. By default, this page shows a general OVERVIEW, a IN COMICS PROFILE and a more specific IN COMICS FULL REPORT.\n",
    "\n",
    "Since not all characters include these last two pieces of information, let's focus on the other elements instead. In particular, we are interested in retrieving part of the information contained in the IN COMICS FULL REPORT tab.\n",
    "\n",
    "We start by retrieving the page HTML soup with *beautifulsoup*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    return bs(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_wiki = get_soup(url_wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now write the code to create a function called get_comics_full_report. This function should take as input a BeautifulSoup object containing the parsed HTML code for a character's wiki website and return the full url for the IN COMICS FULL REPORT tab in string form as output. In cases where no such tag exists, your function should return a None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.marvel.com'\n",
    "def get_comics_full_report(bsoup):\n",
    "    if bsoup.find_all('a',{'class':'masthead__tabs__link'}):\n",
    "        second_soups = bsoup.find_all('a',{'class':'masthead__tabs__link'})\n",
    "        for soups in second_soups:\n",
    "                span_class = soups.find('span',{'class':'masthead__tabs__link-text'}).text\n",
    "                #print(span_class)\n",
    "                if (span_class == 'In Comics Full Report'):\n",
    "                    emp_url = soups.get('href')\n",
    "                    full_url =  base_url + emp_url\n",
    "                    print(str(full_url))\n",
    "    else:\n",
    "        return None\n",
    "get_comics_full_report(soup_wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When accessing the IN COMICS FULL REPORT for a character, we get information about different attributes, including the height, the weight, the gender, etc. Let's write the code to extract this information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight and height\n",
    "\n",
    "Assume that 1 lbs = 0.453592 kg, 1 foot = 30.48 cm and 1 inch = 2.54 cm. In cases where no such information is given, your functions should return a None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_comics_full_report(soup_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_soup = soup_wiki(response)\n",
    "full_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbs = 0.453592 # kg\n",
    "foot = 30.48 # cm\n",
    "inch = 2.54 # cm\n",
    "types = ['feet', 'inches', 'lbs']\n",
    "\n",
    "import re\n",
    "\n",
    "def get_height(soup):\n",
    "    try:\n",
    "        height = soup.find_all(class_='bioheader__stat')[0].text.split(',')[0].split()[-1]\n",
    "        if height == 'None':\n",
    "            return None\n",
    "        else:\n",
    "            # there should be an if statement here to check for the correct type of feet and inches\n",
    "            # if height not in types: return None\n",
    "            height = re.findall('\\d+', height)\n",
    "            if len(height) > 1:\n",
    "                height = (int(height[0]) * foot) + (int(height[1]) * inch)\n",
    "                return height\n",
    "            else:\n",
    "                height = (int(height[0]) * foot) + (int(height[1]) * inch)\n",
    "                return height\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_weight(soup):\n",
    "    try:\n",
    "        weight = soup.find_all(class_='bioheader__stat')[1].text.split(',')[0].split()[-2:]\n",
    "        if weight[1][:-1] not in types:\n",
    "            return None\n",
    "        else:\n",
    "            return lbs * float(weight[0])\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the gender, hair colour and eyes colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender(soup):\n",
    "    stats = soup.find_all('div',{'class': 'bioheader__stats'})\n",
    "    counter = 0\n",
    "    for stat in stats:\n",
    "        if (stat.find('p',{'class': 'bioheader__label'}).text=='gender'):\n",
    "            gender = stat.find('p',{'class':'bioheader__stat'}).text\n",
    "            counter = 1\n",
    "    if counter == 1:\n",
    "        return str(gender)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_eyes(soup):\n",
    "    stats = soup.find_all('div',{'class': 'bioheader__stats'})\n",
    "    counter = 0\n",
    "    for stat in stats:\n",
    "        if (stat.find('p',{'class': 'bioheader__label'}).text=='eyes'):\n",
    "            eyes = stat.find('p',{'class':'bioheader__stat'}).text\n",
    "            counter = 1\n",
    "    if counter == 1:\n",
    "        return str(eyes)\n",
    "  \n",
    "def get_hair(soup):\n",
    "    stats = soup.find_all('div',{'class': 'bioheader__stats'})\n",
    "    counter = 0\n",
    "    for stat in stats:\n",
    "        if (stat.find('p',{'class': 'bioheader__label'}).text=='hair'):\n",
    "            hair = stat.find('p',{'class':'bioheader__stat'}).text\n",
    "            counter = 1\n",
    "    if counter == 1:\n",
    "        return str(hair)\n",
    "    else:\n",
    "        return None\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the place of origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_place_of_origin(soup):\n",
    "    stats = soup.find_all('li',{'class': 'railBioInfo__Item'})\n",
    "    counter = 0\n",
    "    for stat in stats:\n",
    "        if (stat.find('p',{'class': 'railBioInfoItem__label'}).text=='Place of Origin'):\n",
    "            origin = stat.find('ul',{'class':'railBioLinks'}).text\n",
    "            counter = 1\n",
    "    if counter == 1:\n",
    "        return str(origin)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the list of powers\n",
    "We will now create a list to check if our characters contains the following powers : *Flight, Hypnosis, Telepathy, Teleportation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_powers(soup):\n",
    "    stats = soup.find_all('li',{'class': 'railBioInfo__Item'})\n",
    "    counter = 0\n",
    "    powers = [None,None,None,None]\n",
    "    try:\n",
    "        for stat in stats:\n",
    "            if (stat.find('p',{'class': 'railBioInfoItem__label'}).text=='Powers'):\n",
    "                powers_list = stat.find('ul',{'class':'railBioLinks'}).get_text()\n",
    "                counter = 1\n",
    "        if counter == 1:\n",
    "            #check if \"flight\" in powers\n",
    "            power_1 =\"Flight\"\n",
    "            if power_1 in powers_list:\n",
    "                powers[0] = True\n",
    "            #check if \"Hypnosis\" in powers\n",
    "            power_2 =\"Hypnosis\"\n",
    "            if power_2 in powers_list:\n",
    "                powers[1] = True\n",
    "             #check if \"Telepathy\" in powers\n",
    "            power_3 =\"Telepathy\"\n",
    "            if power_3 in powers_list:\n",
    "             #check if \"Teleportation\" in powers\n",
    "                powers[2] = True\n",
    "            power_4 =\"Teleportation\"\n",
    "            if power_4 in powers_list:\n",
    "                powers[3] = True\n",
    "        return powers\n",
    "    except:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the data\n",
    "\n",
    "Let's chose a series on this link: https://www.marvel.com/comics/series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_name = 'Avengers (2018 - Present)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code to make a get request the series/{seriesId}/characters endpoint to fetch the list of the first 100 characters which appear in your chosen series. Store the response in in a new variable called response_characters.\n",
    "\n",
    "*Note that Marvel's API returns information in batches of 100 characters at most. Make a single request, so that if the number of characters in your chosen series is larger than 100 you only retrieve the first 100. If the number of characters in your chosen series is smaller than 100, you should retrieve them all in a single request.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_url = 'https://www.marvel.com/comics/series'\n",
    "soup_id = get_soup(auth_url)\n",
    "ids = soup_id.find('div',{'class': 'JCAZList-list'})\n",
    "\n",
    "for indi_id in ids.find_all('a'):\n",
    "    if indi_id.text == series_name:\n",
    "        href = str(indi_id.get('href'))\n",
    "        hrefs = href.split('/')\n",
    "        series_id = (hrefs[3])\n",
    "\n",
    "        series_endpoint = 'https://gateway.marvel.com/v1/public/series/'+series_id+'/characters'\n",
    "series_url = series_endpoint\n",
    "ts = str(time.time())\n",
    "code = ts+privatekey+publickey\n",
    "md5hash = hashlib.md5(code.encode('utf-8')).hexdigest()\n",
    "params = {'apikey': publickey, \n",
    "          'ts': ts, \n",
    "          'hash': md5hash,\n",
    "          'limit': 100}\n",
    "\n",
    "response_characters = requests.get(series_url, params)\n",
    "response_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, you will retrieve information about each of the characters in your series above separately. For that purpose, let's first identify their names and wiki urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "url_wikis = []\n",
    "\n",
    "for character in response_characters.json()['data']['results']:\n",
    "    names.append(character['name'])\n",
    "    url_wikis.append(character['urls'][1]['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now write the code to retrieve the name, height, weight, gender, eyecolor, haircolor, place of origin and the powers of each of the characters in your chosen series. Store this information in a DataFrame object called marvel. Set the names of the columns to: name, height, weight, gender, eyes, hair, place_of_origin, flight, hypnosis, telepathy and teleportation, respectively. Don't define any index when defining your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "height = []\n",
    "weight = []\n",
    "gender = []\n",
    "eyes = []\n",
    "hair = []\n",
    "place_of_origin = []\n",
    "flight = []\n",
    "hypnosis = []\n",
    "telepathy =[]\n",
    "teleportation =[]\n",
    "\n",
    "for url_wiki in url_wikis:\n",
    "    soup_wiki = get_soup(url_wiki)\n",
    "    if get_comics_full_report(soup_wiki):\n",
    "        url_report = get_comics_full_report(soup_wiki)\n",
    "    \n",
    "        #print(url_report)\n",
    "        soup_report = get_soup(url_report)\n",
    "\n",
    "        height.append(get_height(soup_report))\n",
    "        weight.append(get_weight(soup_report))\n",
    "        gender.append(get_gender(soup_report))\n",
    "        eyes.append(get_eyes(soup_report))\n",
    "        hair.append(get_hair(soup_report))\n",
    "        place_of_origin.append(get_place_of_origin(soup_report))\n",
    "        powers = get_powers(soup_report)\n",
    "        flight.append(powers[0])\n",
    "        hypnosis.append(powers[1])\n",
    "        telepathy.append(powers[2])\n",
    "        teleportation.append(powers[3])\n",
    "        \n",
    "    else:\n",
    "        height.append(None)\n",
    "        weight.append(None)\n",
    "        gender.append(None)\n",
    "        eyes.append(None)\n",
    "        hair.append(None)\n",
    "        place_of_origin.append(None)\n",
    "        flight.append(None)\n",
    "        hypnosis.append(None)\n",
    "        telepathy.append(None)\n",
    "        teleportation.append(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel = pd.DataFrame({'name':names,\n",
    "                   'height':height,\n",
    "                   'weight':weight,\n",
    "                   'gender':gender,\n",
    "                   'eyes':eyes,\n",
    "                   'hair':hair,\n",
    "                   'place_of_origin':place_of_origin,\n",
    "                   'flight':flight,\n",
    "                   'hypnosis':hypnosis,\n",
    "                   'telepathy':telepathy,\n",
    "                   'teleportation':teleportation})\n",
    "marvel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
